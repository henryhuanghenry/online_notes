<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.48">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>线性模型 | Yusheng Huang's page</title><meta name="description" content="">
    <link rel="modulepreload" href="/online_notes/assets/app.6738de7d.js"><link rel="modulepreload" href="/online_notes/assets/线性模型.html.7122beec.js"><link rel="modulepreload" href="/online_notes/assets/线性模型.html.355f8f06.js"><link rel="prefetch" href="/online_notes/assets/index.html.e8bd54db.js"><link rel="prefetch" href="/online_notes/assets/index.html.9cdecf27.js"><link rel="prefetch" href="/online_notes/assets/index.html.f4aa201f.js"><link rel="prefetch" href="/online_notes/assets/动态规划.html.cb310cd6.js"><link rel="prefetch" href="/online_notes/assets/回溯算法.html.9fe6929a.js"><link rel="prefetch" href="/online_notes/assets/排序.html.4f158591.js"><link rel="prefetch" href="/online_notes/assets/链表.html.0aecd45a.js"><link rel="prefetch" href="/online_notes/assets/index.html.1802fd20.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_En.html.a09ddf5d.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_Zh.html.08c5f277.js"><link rel="prefetch" href="/online_notes/assets/基础 -- word embedding.html.509920cf.js"><link rel="prefetch" href="/online_notes/assets/模型 -- Transformer.html.2cf7ffb5.js"><link rel="prefetch" href="/online_notes/assets/index.html.f4330eba.js"><link rel="prefetch" href="/online_notes/assets/attention.html.6393316a.js"><link rel="prefetch" href="/online_notes/assets/推荐系统.html.4825bd30.js"><link rel="prefetch" href="/online_notes/assets/支持向量机.html.97e25085.js"><link rel="prefetch" href="/online_notes/assets/神经网络--Normalization Layers.html.0601d9e9.js"><link rel="prefetch" href="/online_notes/assets/神经网络--RNN_LSTM_GRU.html.58abfa02.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器 - 副本.html.b29c4c4d.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器.html.42e469de.js"><link rel="prefetch" href="/online_notes/assets/神经网络--初始化.html.48c9a2a4.js"><link rel="prefetch" href="/online_notes/assets/神经网络--卷积神经网络.html.a4bf9f4b.js"><link rel="prefetch" href="/online_notes/assets/评价指标.html.84462854.js"><link rel="prefetch" href="/online_notes/assets/集成学习.html.7ba7ed53.js"><link rel="prefetch" href="/online_notes/assets/index.html.f5b5b188.js"><link rel="prefetch" href="/online_notes/assets/哈工大DB-第1讲初步认识数据库.html.abf4f2f7.js"><link rel="prefetch" href="/online_notes/assets/index.html.6df7903f.js"><link rel="prefetch" href="/online_notes/assets/python面试常考.html.631f20d9.js"><link rel="prefetch" href="/online_notes/assets/常用的数据结构和方法.html.fdb91fb0.js"><link rel="prefetch" href="/online_notes/assets/404.html.7d858b3d.js"><link rel="prefetch" href="/online_notes/assets/index.html.4424ba2f.js"><link rel="prefetch" href="/online_notes/assets/index.html.f50c3b1a.js"><link rel="prefetch" href="/online_notes/assets/index.html.df310c58.js"><link rel="prefetch" href="/online_notes/assets/动态规划.html.cd72be07.js"><link rel="prefetch" href="/online_notes/assets/回溯算法.html.4d81f41f.js"><link rel="prefetch" href="/online_notes/assets/排序.html.4d1075a2.js"><link rel="prefetch" href="/online_notes/assets/链表.html.58389072.js"><link rel="prefetch" href="/online_notes/assets/index.html.7b6924f3.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_En.html.b8cf0c10.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_Zh.html.ef9300b9.js"><link rel="prefetch" href="/online_notes/assets/基础 -- word embedding.html.e12b7549.js"><link rel="prefetch" href="/online_notes/assets/模型 -- Transformer.html.7141a756.js"><link rel="prefetch" href="/online_notes/assets/index.html.74cbd8ac.js"><link rel="prefetch" href="/online_notes/assets/attention.html.78d8ebbf.js"><link rel="prefetch" href="/online_notes/assets/推荐系统.html.184b21cb.js"><link rel="prefetch" href="/online_notes/assets/支持向量机.html.27d71670.js"><link rel="prefetch" href="/online_notes/assets/神经网络--Normalization Layers.html.fafc7376.js"><link rel="prefetch" href="/online_notes/assets/神经网络--RNN_LSTM_GRU.html.f5d70023.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器 - 副本.html.3164a93b.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器.html.d73a444f.js"><link rel="prefetch" href="/online_notes/assets/神经网络--初始化.html.84ef72f9.js"><link rel="prefetch" href="/online_notes/assets/神经网络--卷积神经网络.html.2a3937f7.js"><link rel="prefetch" href="/online_notes/assets/评价指标.html.82ffab2c.js"><link rel="prefetch" href="/online_notes/assets/集成学习.html.c3a2ad75.js"><link rel="prefetch" href="/online_notes/assets/index.html.ddd25056.js"><link rel="prefetch" href="/online_notes/assets/哈工大DB-第1讲初步认识数据库.html.8aff3165.js"><link rel="prefetch" href="/online_notes/assets/index.html.6ab3001c.js"><link rel="prefetch" href="/online_notes/assets/python面试常考.html.24d84bbf.js"><link rel="prefetch" href="/online_notes/assets/常用的数据结构和方法.html.58a824ff.js"><link rel="prefetch" href="/online_notes/assets/404.html.29cbe041.js"><link rel="prefetch" href="/online_notes/assets/404.db4ce124.js"><link rel="prefetch" href="/online_notes/assets/Layout.02d8a76f.js">
    <link rel="stylesheet" href="/online_notes/assets/style.504115f4.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/online_notes/" class=""><!----><span class="site-name">Yusheng Huang&#39;s page</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/CSclass/CSclass_DB/README.md" class="" aria-label="数据库"><!--[--><!--]--> 数据库 <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/online_notes/Algorithm/README.md" class="" aria-label="算法"><!--[--><!--]--> 算法 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/AI/基础/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/online_notes/AI/NLP/README.md" class="" aria-label="NLP"><!--[--><!--]--> NLP <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/Programming/python/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/CSclass/CSclass_DB/README.md" class="" aria-label="数据库"><!--[--><!--]--> 数据库 <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/online_notes/Algorithm/README.md" class="" aria-label="算法"><!--[--><!--]--> 算法 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/AI/基础/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/online_notes/AI/NLP/README.md" class="" aria-label="NLP"><!--[--><!--]--> NLP <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/Programming/python/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading active collapsible">AI基础 <span class="down arrow"></span></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/" class="router-link-active sidebar-item" aria-label="机器学习/深度学习--基础"><!--[--><!--]--> 机器学习/深度学习--基础 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/attention.html" class="sidebar-item" aria-label="Attention"><!--[--><!--]--> Attention <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html" class="sidebar-item" aria-label="推荐系统"><!--[--><!--]--> 推荐系统 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html" class="sidebar-item" aria-label="支持向量机"><!--[--><!--]--> 支持向量机 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--Normalization%20Layers.html" class="sidebar-item" aria-label="基础神经网络--Layer Norm"><!--[--><!--]--> 基础神经网络--Layer Norm <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN+LSTM+GRU.html" class="sidebar-item" aria-label="神经网络--RNN|LSTM|GRU"><!--[--><!--]--> 神经网络--RNN|LSTM|GRU <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8%20-%20%E5%89%AF%E6%9C%AC.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%88%9D%E5%A7%8B%E5%8C%96.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" class="sidebar-item" aria-label="基础神经网络--卷积神经网络"><!--[--><!--]--> 基础神经网络--卷积神经网络 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="线性模型"><!--[--><!--]--> 线性模型 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_0-参考资料" class="router-link-active router-link-exact-active sidebar-item" aria-label="0.参考资料："><!--[--><!--]--> 0.参考资料： <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_00-补充数学知识" class="router-link-active router-link-exact-active sidebar-item" aria-label="00 补充数学知识："><!--[--><!--]--> 00 补充数学知识： <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-什么是方差的无偏估计" class="router-link-active router-link-exact-active sidebar-item" aria-label="1. 什么是方差的无偏估计"><!--[--><!--]--> 1. 什么是方差的无偏估计 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-先验后验" class="router-link-active router-link-exact-active sidebar-item" aria-label="2. 先验后验"><!--[--><!--]--> 2. 先验后验 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_3-概率分布" class="router-link-active router-link-exact-active sidebar-item" aria-label="3. 概率分布"><!--[--><!--]--> 3. 概率分布 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-线性回归" class="router-link-active router-link-exact-active sidebar-item" aria-label="1. 线性回归"><!--[--><!--]--> 1. 线性回归 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" class="router-link-active router-link-exact-active sidebar-item" aria-label="1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)"><!--[--><!--]--> 1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法) <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" class="router-link-active router-link-exact-active sidebar-item" aria-label="1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计"><!--[--><!--]--> 1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-3-正则化其实是对模型参数的最大后验" class="router-link-active router-link-exact-active sidebar-item" aria-label="1.3 正则化其实是对模型参数的最大后验"><!--[--><!--]--> 1.3 正则化其实是对模型参数的最大后验 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-逻辑回归-对数几率函数为输出-极大似然法" class="router-link-active router-link-exact-active sidebar-item" aria-label="2. 逻辑回归--对数几率函数为输出，极大似然法"><!--[--><!--]--> 2. 逻辑回归--对数几率函数为输出，极大似然法 <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-1-模型的输出" class="router-link-active router-link-exact-active sidebar-item" aria-label="2.1 模型的输出"><!--[--><!--]--> 2.1 模型的输出 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-2-模型的损失函数及梯度" class="router-link-active router-link-exact-active sidebar-item" aria-label="2.2 模型的损失函数及梯度"><!--[--><!--]--> 2.2 模型的损失函数及梯度 <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" class="sidebar-item" aria-label="评价指标"><!--[--><!--]--> 评价指标 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="集成学习"><!--[--><!--]--> 集成学习 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading collapsible">NLP <span class="right arrow"></span></p><ul style="display:none;" class="sidebar-item-children"><!--[--><li><a href="/online_notes/AI/NLP/%E5%9F%BA%E7%A1%80%20--%20word%20embedding.html" class="sidebar-item" aria-label="基础 -- Transformer"><!--[--><!--]--> 基础 -- Transformer <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html" class="sidebar-item" aria-label="基础 -- Transformer"><!--[--><!--]--> 基础 -- Transformer <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="线性模型" tabindex="-1"><a class="header-anchor" href="#线性模型" aria-hidden="true">#</a> 线性模型</h1><nav class="table-of-contents"><ul><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_0-参考资料" class="router-link-active router-link-exact-active">0.参考资料：</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_00-补充数学知识" class="router-link-active router-link-exact-active">00 补充数学知识：</a><ul><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-什么是方差的无偏估计" class="router-link-active router-link-exact-active">1. 什么是方差的无偏估计</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-先验后验" class="router-link-active router-link-exact-active">2. 先验后验</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_3-概率分布" class="router-link-active router-link-exact-active">3. 概率分布</a></li></ul></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-线性回归" class="router-link-active router-link-exact-active">1. 线性回归</a><ul><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" class="router-link-active router-link-exact-active">1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" class="router-link-active router-link-exact-active">1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_1-3-正则化其实是对模型参数的最大后验" class="router-link-active router-link-exact-active">1.3 正则化其实是对模型参数的最大后验</a></li></ul></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-逻辑回归-对数几率函数为输出-极大似然法" class="router-link-active router-link-exact-active">2. 逻辑回归--对数几率函数为输出，极大似然法</a><ul><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-1-模型的输出" class="router-link-active router-link-exact-active">2.1 模型的输出</a></li><li><a aria-current="page" href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html#_2-2-模型的损失函数及梯度" class="router-link-active router-link-exact-active">2.2 模型的损失函数及梯度</a></li></ul></li></ul></nav><h2 id="_0-参考资料" tabindex="-1"><a class="header-anchor" href="#_0-参考资料" aria-hidden="true">#</a> 0.参考资料：</h2><ul><li></li><li><p>ROC可以更聚焦于模型本身，降低测试集带来的干扰</p></li></ul><h2 id="_00-补充数学知识" tabindex="-1"><a class="header-anchor" href="#_00-补充数学知识" aria-hidden="true">#</a> 00 补充数学知识：</h2><h3 id="_1-什么是方差的无偏估计" tabindex="-1"><a class="header-anchor" href="#_1-什么是方差的无偏估计" aria-hidden="true">#</a> 1. 什么是方差的无偏估计</h3><p>参考：</p><ul><li><a href="https://www.zhihu.com/question/20099757/answer/26586088" target="_blank" rel="noopener noreferrer">为什么样本方差（sample variance）的分母是 n-1<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></li><li></li></ul><h4 id="随机变量期望已知时-计算方差" tabindex="-1"><a class="header-anchor" href="#随机变量期望已知时-计算方差" aria-hidden="true">#</a> 随机变量期望已知时，计算方差</h4><p>TBD 需要补充中心极限定理</p><img src="/online_notes/assets/image-20220628201816396.91d9ae7c.png" alt="image-20220628201816396" style="zoom:67%;"><h4 id="随机变量期望未知时-方差的有偏估计" tabindex="-1"><a class="header-anchor" href="#随机变量期望未知时-方差的有偏估计" aria-hidden="true">#</a> 随机变量期望未知时，方差的有偏估计</h4><img src="/online_notes/assets/image-20220628201940536.f85992e2.png" alt="image-20220628201940536" style="zoom:67%;"><img src="/online_notes/assets/image-20220628202019376.514e0941.png" alt="image-20220628202019376" style="zoom:80%;"><h4 id="方差无偏估计" tabindex="-1"><a class="header-anchor" href="#方差无偏估计" aria-hidden="true">#</a> 方差无偏估计</h4><p><a href="https://www.zhihu.com/question/20099757/answer/312670291" target="_blank" rel="noopener noreferrer">参考为什么样本方差（sample variance）的分母是 n-1？ - 马同学的回答 - 知乎<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p><img src="/online_notes/assets/-16564189436151.addbbfc6.svg" alt="[公式]" style="zoom:67%;"><img src="/online_notes/assets/image-20220628202430436.7dc584f3.png" alt="image-20220628202430436" style="zoom:67%;"><h3 id="_2-先验后验" tabindex="-1"><a class="header-anchor" href="#_2-先验后验" aria-hidden="true">#</a> 2. 先验后验</h3><img src="/online_notes/assets/image-20220628204135615.9e981881.png" alt="image-20220628204135615" style="zoom:50%;"><h3 id="_3-概率分布" tabindex="-1"><a class="header-anchor" href="#_3-概率分布" aria-hidden="true">#</a> 3. 概率分布</h3><img src="/online_notes/assets/image-20220628204859364.0b5a31d7.png" alt="image-20220628204859364" style="zoom:67%;"><h2 id="_1-线性回归" tabindex="-1"><a class="header-anchor" href="#_1-线性回归" aria-hidden="true">#</a> 1. 线性回归</h2><h3 id="_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" tabindex="-1"><a class="header-anchor" href="#_1-1-视角1-直接选择均方误差为损失函数-最小化损失-最小二乘法" aria-hidden="true">#</a> 1.1 视角1：直接选择均方误差为损失函数，最小化损失(最小二乘法)</h3><img src="/online_notes/assets/image-20220628204233396.8fadcd0d.png" alt="image-20220628204233396" style="zoom:50%;"><img src="/online_notes/assets/image-20220628204256965.cb67addd.png" alt="image-20220628204256965" style="zoom:50%;"><h3 id="_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" tabindex="-1"><a class="header-anchor" href="#_1-2-视角2-假定模型输出含有高斯白噪声-高斯函数分布为似然函数-极大似然估计" aria-hidden="true">#</a> 1.2 视角2：假定模型输出含有高斯白噪声，高斯函数分布为似然函数，极大似然估计</h3><img src="/online_notes/assets/image-20220628204342147.45095ff1.png" alt="image-20220628204342147" style="zoom:67%;"><img src="/online_notes/assets/image-20220628204424950.6477878a.png" alt="image-20220628204424950" style="zoom:67%;"><h3 id="_1-3-正则化其实是对模型参数的最大后验" tabindex="-1"><a class="header-anchor" href="#_1-3-正则化其实是对模型参数的最大后验" aria-hidden="true">#</a> 1.3 正则化其实是对模型参数的最大后验</h3><img src="/online_notes/assets/image-20220628204803472.0537b1e0.png" alt="image-20220628204803472" style="zoom:67%;"><h2 id="_2-逻辑回归-对数几率函数为输出-极大似然法" tabindex="-1"><a class="header-anchor" href="#_2-逻辑回归-对数几率函数为输出-极大似然法" aria-hidden="true">#</a> 2. 逻辑回归--对数几率函数为输出，极大似然法</h2><p><strong>核心在于，如何从对数几率函数推导出似然函数，再推导出损失函数与导数</strong></p><ul><li>逻辑回归其实是想用线性模型去完成一个分类任务</li><li>因此，选择对数几率函数（sigmoid是形似S的函数，对数几率函数是代表）作为模型的输出，就可以起到二分类的作用</li><li>详细的推导见《机器学习》--周志华</li></ul><h3 id="_2-1-模型的输出" tabindex="-1"><a class="header-anchor" href="#_2-1-模型的输出" aria-hidden="true">#</a> 2.1 模型的输出</h3><img src="/online_notes/assets/image-20220628195415624.a307e14c.png" alt="image-20220628195415624" style="zoom:50%;"><p><strong>把式子中的y视为类别概率的话，我们就可以得出模型的似然函数</strong></p><img src="/online_notes/assets/image-20220628195652966.44284cec.png" alt="image-20220628195652966" style="zoom:50%;"><h3 id="_2-2-模型的损失函数及梯度" tabindex="-1"><a class="header-anchor" href="#_2-2-模型的损失函数及梯度" aria-hidden="true">#</a> 2.2 模型的损失函数及梯度</h3><p><strong>使用极大似然法，最大化模型的对数似然</strong></p><img src="/online_notes/assets/image-20220628195851091.6964a36a.png" alt="image-20220628195851091" style="zoom:67%;"><p>而后求出导数就行了</p><img src="/online_notes/assets/image-20220628195928191.d282ef43.png" alt="image-20220628195928191" style="zoom:67%;"></div><!--[--><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: henryhuanghenry@outlook.com">henryhuang</span><!----><!--]--><!--]--></span></div></footer><nav class="page-nav"><p class="inner"><span class="prev"><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" class="" aria-label="基础神经网络--卷积神经网络"><!--[--><!--]--> 基础神经网络--卷积神经网络 <!--[--><!--]--></a></span><span class="next"><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" class="" aria-label="评价指标"><!--[--><!--]--> 评价指标 <!--[--><!--]--></a></span></p></nav><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/online_notes/assets/app.6738de7d.js" defer></script>
  </body>
</html>
