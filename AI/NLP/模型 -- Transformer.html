<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="generator" content="VuePress 2.0.0-beta.48">
    <style>
      :root {
        --c-bg: #fff;
      }
      html.dark {
        --c-bg: #22272e;
      }
      html, body {
        background-color: var(--c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem('vuepress-color-scheme');
			const systemDarkMode = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;
			if (userMode === 'dark' || (userMode !== 'light' && systemDarkMode)) {
				document.documentElement.classList.toggle('dark', true);
			}
    </script>
    <title>基础 -- Transformer | Yusheng Huang's page</title><meta name="description" content="">
    <link rel="modulepreload" href="/online_notes/assets/app.6738de7d.js"><link rel="modulepreload" href="/online_notes/assets/模型 -- Transformer.html.7141a756.js"><link rel="modulepreload" href="/online_notes/assets/模型 -- Transformer.html.2cf7ffb5.js"><link rel="prefetch" href="/online_notes/assets/index.html.e8bd54db.js"><link rel="prefetch" href="/online_notes/assets/index.html.9cdecf27.js"><link rel="prefetch" href="/online_notes/assets/index.html.f4aa201f.js"><link rel="prefetch" href="/online_notes/assets/动态规划.html.cb310cd6.js"><link rel="prefetch" href="/online_notes/assets/回溯算法.html.9fe6929a.js"><link rel="prefetch" href="/online_notes/assets/排序.html.4f158591.js"><link rel="prefetch" href="/online_notes/assets/链表.html.0aecd45a.js"><link rel="prefetch" href="/online_notes/assets/index.html.1802fd20.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_En.html.a09ddf5d.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_Zh.html.08c5f277.js"><link rel="prefetch" href="/online_notes/assets/基础 -- word embedding.html.509920cf.js"><link rel="prefetch" href="/online_notes/assets/index.html.f4330eba.js"><link rel="prefetch" href="/online_notes/assets/attention.html.6393316a.js"><link rel="prefetch" href="/online_notes/assets/推荐系统.html.4825bd30.js"><link rel="prefetch" href="/online_notes/assets/支持向量机.html.97e25085.js"><link rel="prefetch" href="/online_notes/assets/神经网络--Normalization Layers.html.0601d9e9.js"><link rel="prefetch" href="/online_notes/assets/神经网络--RNN_LSTM_GRU.html.58abfa02.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器 - 副本.html.b29c4c4d.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器.html.42e469de.js"><link rel="prefetch" href="/online_notes/assets/神经网络--初始化.html.48c9a2a4.js"><link rel="prefetch" href="/online_notes/assets/神经网络--卷积神经网络.html.a4bf9f4b.js"><link rel="prefetch" href="/online_notes/assets/线性模型.html.355f8f06.js"><link rel="prefetch" href="/online_notes/assets/评价指标.html.84462854.js"><link rel="prefetch" href="/online_notes/assets/集成学习.html.7ba7ed53.js"><link rel="prefetch" href="/online_notes/assets/index.html.f5b5b188.js"><link rel="prefetch" href="/online_notes/assets/哈工大DB-第1讲初步认识数据库.html.abf4f2f7.js"><link rel="prefetch" href="/online_notes/assets/index.html.6df7903f.js"><link rel="prefetch" href="/online_notes/assets/python面试常考.html.631f20d9.js"><link rel="prefetch" href="/online_notes/assets/常用的数据结构和方法.html.fdb91fb0.js"><link rel="prefetch" href="/online_notes/assets/404.html.7d858b3d.js"><link rel="prefetch" href="/online_notes/assets/index.html.4424ba2f.js"><link rel="prefetch" href="/online_notes/assets/index.html.f50c3b1a.js"><link rel="prefetch" href="/online_notes/assets/index.html.df310c58.js"><link rel="prefetch" href="/online_notes/assets/动态规划.html.cd72be07.js"><link rel="prefetch" href="/online_notes/assets/回溯算法.html.4d81f41f.js"><link rel="prefetch" href="/online_notes/assets/排序.html.4d1075a2.js"><link rel="prefetch" href="/online_notes/assets/链表.html.58389072.js"><link rel="prefetch" href="/online_notes/assets/index.html.7b6924f3.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_En.html.b8cf0c10.js"><link rel="prefetch" href="/online_notes/assets/simple_resume_Zh.html.ef9300b9.js"><link rel="prefetch" href="/online_notes/assets/基础 -- word embedding.html.e12b7549.js"><link rel="prefetch" href="/online_notes/assets/index.html.74cbd8ac.js"><link rel="prefetch" href="/online_notes/assets/attention.html.78d8ebbf.js"><link rel="prefetch" href="/online_notes/assets/推荐系统.html.184b21cb.js"><link rel="prefetch" href="/online_notes/assets/支持向量机.html.27d71670.js"><link rel="prefetch" href="/online_notes/assets/神经网络--Normalization Layers.html.fafc7376.js"><link rel="prefetch" href="/online_notes/assets/神经网络--RNN_LSTM_GRU.html.f5d70023.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器 - 副本.html.3164a93b.js"><link rel="prefetch" href="/online_notes/assets/神经网络--优化器.html.d73a444f.js"><link rel="prefetch" href="/online_notes/assets/神经网络--初始化.html.84ef72f9.js"><link rel="prefetch" href="/online_notes/assets/神经网络--卷积神经网络.html.2a3937f7.js"><link rel="prefetch" href="/online_notes/assets/线性模型.html.7122beec.js"><link rel="prefetch" href="/online_notes/assets/评价指标.html.82ffab2c.js"><link rel="prefetch" href="/online_notes/assets/集成学习.html.c3a2ad75.js"><link rel="prefetch" href="/online_notes/assets/index.html.ddd25056.js"><link rel="prefetch" href="/online_notes/assets/哈工大DB-第1讲初步认识数据库.html.8aff3165.js"><link rel="prefetch" href="/online_notes/assets/index.html.6ab3001c.js"><link rel="prefetch" href="/online_notes/assets/python面试常考.html.24d84bbf.js"><link rel="prefetch" href="/online_notes/assets/常用的数据结构和方法.html.58a824ff.js"><link rel="prefetch" href="/online_notes/assets/404.html.29cbe041.js"><link rel="prefetch" href="/online_notes/assets/404.db4ce124.js"><link rel="prefetch" href="/online_notes/assets/Layout.02d8a76f.js">
    <link rel="stylesheet" href="/online_notes/assets/style.504115f4.css">
  </head>
  <body>
    <div id="app"><!--[--><div class="theme-container"><!--[--><header class="navbar"><div class="toggle-sidebar-button" title="toggle sidebar" aria-expanded="false" role="button" tabindex="0"><div class="icon" aria-hidden="true"><span></span><span></span><span></span></div></div><span><a href="/online_notes/" class=""><!----><span class="site-name">Yusheng Huang&#39;s page</span></a></span><div class="navbar-items-wrapper" style=""><!--[--><!--]--><nav class="navbar-items can-hide"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/CSclass/CSclass_DB/README.md" class="" aria-label="数据库"><!--[--><!--]--> 数据库 <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/online_notes/Algorithm/README.md" class="" aria-label="算法"><!--[--><!--]--> 算法 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/AI/基础/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/online_notes/AI/NLP/README.md" class="router-link-active" aria-label="NLP"><!--[--><!--]--> NLP <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/Programming/python/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><button class="toggle-color-mode-button" title="toggle color mode"><svg style="" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M16 12.005a4 4 0 1 1-4 4a4.005 4.005 0 0 1 4-4m0-2a6 6 0 1 0 6 6a6 6 0 0 0-6-6z" fill="currentColor"></path><path d="M5.394 6.813l1.414-1.415l3.506 3.506L8.9 10.318z" fill="currentColor"></path><path d="M2 15.005h5v2H2z" fill="currentColor"></path><path d="M5.394 25.197L8.9 21.691l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 25.005h2v5h-2z" fill="currentColor"></path><path d="M21.687 23.106l1.414-1.415l3.506 3.506l-1.414 1.414z" fill="currentColor"></path><path d="M25 15.005h5v2h-5z" fill="currentColor"></path><path d="M21.687 8.904l3.506-3.506l1.414 1.415l-3.506 3.505z" fill="currentColor"></path><path d="M15 2.005h2v5h-2z" fill="currentColor"></path></svg><svg style="display:none;" class="icon" focusable="false" viewBox="0 0 32 32"><path d="M13.502 5.414a15.075 15.075 0 0 0 11.594 18.194a11.113 11.113 0 0 1-7.975 3.39c-.138 0-.278.005-.418 0a11.094 11.094 0 0 1-3.2-21.584M14.98 3a1.002 1.002 0 0 0-.175.016a13.096 13.096 0 0 0 1.825 25.981c.164.006.328 0 .49 0a13.072 13.072 0 0 0 10.703-5.555a1.01 1.01 0 0 0-.783-1.565A13.08 13.08 0 0 1 15.89 4.38A1.015 1.015 0 0 0 14.98 3z" fill="currentColor"></path></svg></button><!----></div></header><!--]--><div class="sidebar-mask"></div><!--[--><aside class="sidebar"><nav class="navbar-items"><!--[--><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="基础课程笔记"><span class="title">基础课程笔记</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/CSclass/CSclass_DB/README.md" class="" aria-label="数据库"><!--[--><!--]--> 数据库 <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><a href="/online_notes/Algorithm/README.md" class="" aria-label="算法"><!--[--><!--]--> 算法 <!--[--><!--]--></a></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="AI"><span class="title">AI</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="AI"><span class="title">AI</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/AI/基础/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><li class="navbar-dropdown-item"><a href="/online_notes/AI/NLP/README.md" class="router-link-active" aria-label="NLP"><!--[--><!--]--> NLP <!--[--><!--]--></a></li><!--]--></ul></div></div><div class="navbar-item"><div class="navbar-dropdown-wrapper"><button class="navbar-dropdown-title" type="button" aria-label="编程"><span class="title">编程</span><span class="arrow down"></span></button><button class="navbar-dropdown-title-mobile" type="button" aria-label="编程"><span class="title">编程</span><span class="right arrow"></span></button><ul style="display:none;" class="navbar-dropdown"><!--[--><li class="navbar-dropdown-item"><a href="/online_notes/Programming/python/README.md" class="" aria-label="基础"><!--[--><!--]--> 基础 <!--[--><!--]--></a></li><!--]--></ul></div></div><!--]--></nav><!--[--><!--]--><ul class="sidebar-items"><!--[--><li><p tabindex="0" class="sidebar-item sidebar-heading collapsible">AI基础 <span class="right arrow"></span></p><ul style="display:none;" class="sidebar-item-children"><!--[--><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/" class="sidebar-item" aria-label="机器学习/深度学习--基础"><!--[--><!--]--> 机器学习/深度学习--基础 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/attention.html" class="sidebar-item" aria-label="Attention"><!--[--><!--]--> Attention <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F.html" class="sidebar-item" aria-label="推荐系统"><!--[--><!--]--> 推荐系统 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.html" class="sidebar-item" aria-label="支持向量机"><!--[--><!--]--> 支持向量机 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--Normalization%20Layers.html" class="sidebar-item" aria-label="基础神经网络--Layer Norm"><!--[--><!--]--> 基础神经网络--Layer Norm <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--RNN+LSTM+GRU.html" class="sidebar-item" aria-label="神经网络--RNN|LSTM|GRU"><!--[--><!--]--> 神经网络--RNN|LSTM|GRU <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8%20-%20%E5%89%AF%E6%9C%AC.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E4%BC%98%E5%8C%96%E5%99%A8.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%88%9D%E5%A7%8B%E5%8C%96.html" class="sidebar-item" aria-label="基础神经网络--优化器"><!--[--><!--]--> 基础神经网络--优化器 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C--%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C.html" class="sidebar-item" aria-label="基础神经网络--卷积神经网络"><!--[--><!--]--> 基础神经网络--卷积神经网络 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B.html" class="sidebar-item" aria-label="线性模型"><!--[--><!--]--> 线性模型 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" class="sidebar-item" aria-label="评价指标"><!--[--><!--]--> 评价指标 <!--[--><!--]--></a><!----></li><li><a href="/online_notes/AI/%E5%9F%BA%E7%A1%80/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0.html" class="sidebar-item" aria-label="集成学习"><!--[--><!--]--> 集成学习 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><p tabindex="0" class="sidebar-item sidebar-heading active collapsible">NLP <span class="down arrow"></span></p><ul style="" class="sidebar-item-children"><!--[--><li><a href="/online_notes/AI/NLP/%E5%9F%BA%E7%A1%80%20--%20word%20embedding.html" class="sidebar-item" aria-label="基础 -- Transformer"><!--[--><!--]--> 基础 -- Transformer <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html" class="router-link-active router-link-exact-active router-link-active sidebar-item active" aria-label="基础 -- Transformer"><!--[--><!--]--> 基础 -- Transformer <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-资料网址" class="router-link-active router-link-exact-active sidebar-item" aria-label="0.资料网址："><!--[--><!--]--> 0.资料网址： <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-positional-encodering" class="router-link-active router-link-exact-active sidebar-item" aria-label="0. positional encodering"><!--[--><!--]--> 0. positional encodering <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-1-为什么需要positional-encodering-普通的为何不行" class="router-link-active router-link-exact-active sidebar-item" aria-label="0.1 为什么需要positional encodering，普通的为何不行"><!--[--><!--]--> 0.1 为什么需要positional encodering，普通的为何不行 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-2-位置编码需要的特性" class="router-link-active router-link-exact-active sidebar-item" aria-label="0.2 位置编码需要的特性"><!--[--><!--]--> 0.2 位置编码需要的特性 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-3-当前的位置编码" class="router-link-active router-link-exact-active sidebar-item" aria-label="0.3 当前的位置编码"><!--[--><!--]--> 0.3 当前的位置编码 <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-self-attention" class="router-link-active router-link-exact-active sidebar-item" aria-label="1. self-attention"><!--[--><!--]--> 1. self-attention <!--[--><!--]--></a><ul style="" class="sidebar-item-children"><!--[--><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-1-归一化" class="router-link-active router-link-exact-active sidebar-item" aria-label="1.1 归一化"><!--[--><!--]--> 1.1 归一化 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-2-如何mask" class="router-link-active router-link-exact-active sidebar-item" aria-label="1.2 如何mask"><!--[--><!--]--> 1.2 如何mask <!--[--><!--]--></a><!----></li><!--]--></ul></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_2-多头注意力" class="router-link-active router-link-exact-active sidebar-item" aria-label="2. 多头注意力"><!--[--><!--]--> 2. 多头注意力 <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_3-point-wise-ffn" class="router-link-active router-link-exact-active sidebar-item" aria-label="3. Point-wise FFN"><!--[--><!--]--> 3. Point-wise FFN <!--[--><!--]--></a><!----></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_4-模型参数计算" class="router-link-active router-link-exact-active sidebar-item" aria-label="4. 模型参数计算"><!--[--><!--]--> 4. 模型参数计算 <!--[--><!--]--></a><!----></li><!--]--></ul></li><!--]--></ul></li><!--]--></ul><!--[--><!--]--></aside><!--]--><!--[--><main class="page"><!--[--><!--]--><div class="theme-default-content"><!--[--><!--]--><div><h1 id="基础-transformer" tabindex="-1"><a class="header-anchor" href="#基础-transformer" aria-hidden="true">#</a> 基础 -- Transformer</h1><nav class="table-of-contents"><ul><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-资料网址" class="router-link-active router-link-exact-active">0.资料网址：</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-positional-encodering" class="router-link-active router-link-exact-active">0. positional encodering</a><ul><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-1-为什么需要positional-encodering-普通的为何不行" class="router-link-active router-link-exact-active">0.1 为什么需要positional encodering，普通的为何不行</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-2-位置编码需要的特性" class="router-link-active router-link-exact-active">0.2 位置编码需要的特性</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_0-3-当前的位置编码" class="router-link-active router-link-exact-active">0.3 当前的位置编码</a></li></ul></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-self-attention" class="router-link-active router-link-exact-active">1. self-attention</a><ul><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-1-归一化" class="router-link-active router-link-exact-active">1.1 归一化</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_1-2-如何mask" class="router-link-active router-link-exact-active">1.2 如何mask</a></li></ul></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_2-多头注意力" class="router-link-active router-link-exact-active">2. 多头注意力</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_3-point-wise-ffn" class="router-link-active router-link-exact-active">3. Point-wise FFN</a></li><li><a aria-current="page" href="/online_notes/AI/NLP/%E6%A8%A1%E5%9E%8B%20--%20Transformer.html#_4-模型参数计算" class="router-link-active router-link-exact-active">4. 模型参数计算</a></li></ul></nav><h2 id="_0-资料网址" tabindex="-1"><a class="header-anchor" href="#_0-资料网址" aria-hidden="true">#</a> 0.资料网址：</h2><ul><li><p><a href="https://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener noreferrer">详细的解释<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></li><li><p><a href="https://classic.d2l.ai/chapter_attention-mechanism/transformer.html" target="_blank" rel="noopener noreferrer">d2l网址<span><svg class="external-link-icon" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewbox="0 0 100 100" width="15" height="15"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg><span class="external-link-icon-sr-only">open in new window</span></span></a></p></li></ul><h2 id="_0-positional-encodering" tabindex="-1"><a class="header-anchor" href="#_0-positional-encodering" aria-hidden="true">#</a> 0. positional encodering</h2><ul><li>参考网址https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</li><li>对于当前posititonal encodering的相对位置的证明https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/</li></ul><h3 id="_0-1-为什么需要positional-encodering-普通的为何不行" tabindex="-1"><a class="header-anchor" href="#_0-1-为什么需要positional-encodering-普通的为何不行" aria-hidden="true">#</a> 0.1 为什么需要positional encodering，普通的为何不行</h3><ul><li><p>模型需要对位置有个概念，需要知道单词的先后顺序</p></li><li><p>但是因为attention的存在，所有的单词是同时间输入到模型的</p></li><li><p>为何不能简单的用[0,1]或者[1,2, , length_word]对每个单词进行赋值</p><ul><li>简单的用[0,1]的话，不同句子长度不一样，而每个不同长度的句子，数值间隔步长就不一样 <ul><li>比如长度为5的句子单词间隔0.2，长度为10的句子单词间隔0.1</li><li>这样就导致了，单词的数值间隔的不一致，难以表征顺序，影响学习</li></ul></li><li>如果使用[1,2, , length_word]的话 <ul><li>模型的输入的句子的长度不一致，如果位置编码与长度相关的话，如果模型没见过一些长度的句子，也容易影响学习</li><li>比如常见的都是12长的，如果输入100长的，后面的位置编码模型都没见过</li></ul></li></ul></li></ul><h3 id="_0-2-位置编码需要的特性" tabindex="-1"><a class="header-anchor" href="#_0-2-位置编码需要的特性" aria-hidden="true">#</a> 0.2 位置编码需要的特性</h3><blockquote><p>Ideally, the following criteria should be satisfied:</p><ul><li>It should output a unique encoding for each time-step (word’s position in a sentence)</li><li>Distance between any two time-steps should be consistent across sentences with different lengths.</li><li>Our model should generalize to longer sentences without any efforts. Its values should be bounded.</li><li>It must be deterministic.</li></ul></blockquote><ul><li>编码是确定性的，不取决于输入长度</li><li>每一个位置编码唯一</li><li>每两个位置的相对间隔是一致的，如1和2 以及 5和6 之间需要有一致的间隔，比如0.1</li><li>可以使用更长的输入序列</li></ul><h3 id="_0-3-当前的位置编码" tabindex="-1"><a class="header-anchor" href="#_0-3-当前的位置编码" aria-hidden="true">#</a> 0.3 当前的位置编码</h3><p><img src="/online_notes/assets/image-20220703170022145.bfe34db8.png" alt="image-20220703170022145"></p><h2 id="_1-self-attention" tabindex="-1"><a class="header-anchor" href="#_1-self-attention" aria-hidden="true">#</a> 1. self-attention</h2><img src="/online_notes/assets/image-20220703170222560.ce7a0d82.png" alt="image-20220703170222560" style="zoom:150%;"><h3 id="_1-1-归一化" tabindex="-1"><a class="header-anchor" href="#_1-1-归一化" aria-hidden="true">#</a> 1.1 归一化</h3><p>为何要除以根号dk，是因为，相乘求和之后，方差为变大变为原来的dk倍数。</p><ul><li>因此，除以根号dk其实是一个z的归一化，使其方差继续变为1</li></ul><h3 id="_1-2-如何mask" tabindex="-1"><a class="header-anchor" href="#_1-2-如何mask" aria-hidden="true">#</a> 1.2 如何mask</h3><p><img src="/online_notes/assets/image-20220703171135294.eddb35c9.png" alt="image-20220703171135294"></p><h2 id="_2-多头注意力" tabindex="-1"><a class="header-anchor" href="#_2-多头注意力" aria-hidden="true">#</a> 2. 多头注意力</h2><p><img src="/online_notes/assets/image-20220703170245345.9b1b3aad.png" alt="image-20220703170245345"></p><h2 id="_3-point-wise-ffn" tabindex="-1"><a class="header-anchor" href="#_3-point-wise-ffn" aria-hidden="true">#</a> 3. Point-wise FFN</h2><img src="/online_notes/assets/image-20220703170255013.0c64d5b0.png" alt="image-20220703170255013" style="zoom:150%;"><h2 id="_4-模型参数计算" tabindex="-1"><a class="header-anchor" href="#_4-模型参数计算" aria-hidden="true">#</a> 4. 模型参数计算</h2><img src="/online_notes/assets/image-20220703170307202.7d609cd0.png" alt="image-20220703170307202" style="zoom:80%;"></div><!--[--><!--]--></div><footer class="page-meta"><!----><div class="meta-item last-updated"><span class="meta-item-label">Last Updated: </span><!----></div><div class="meta-item contributors"><span class="meta-item-label">Contributors: </span><span class="meta-item-info"><!--[--><!--[--><span class="contributor" title="email: henryhuanghenry@outlook.com">henryhuang</span><!----><!--]--><!--]--></span></div></footer><nav class="page-nav"><p class="inner"><span class="prev"><a href="/online_notes/AI/NLP/%E5%9F%BA%E7%A1%80%20--%20word%20embedding.html" class="" aria-label="基础 -- Transformer"><!--[--><!--]--> 基础 -- Transformer <!--[--><!--]--></a></span><!----></p></nav><!--[--><!--]--></main><!--]--></div><!----><!--]--></div>
    <script type="module" src="/online_notes/assets/app.6738de7d.js" defer></script>
  </body>
</html>
